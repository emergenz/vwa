% !TeX root = document.tex
\chapter{Probleme einer allgemeinen künstlichen Intelligenz}
\section{Fehlerhafte Vorstellungen einer KI-Katastrophe}
In der allgemeinen Bevölkerung überwiegen fehlerhafte Vorstellungen einer KI-Katastrophe. Die folgenden Unterkapitel dienen der Aufklärung von Missverständnissen und Mythen.
\subsection{KI, die ein Bewusstsein erlangt}
In der Laienwelt sowie in großen Teilen der KI-Forschung ist eine These bekannt, die besagt, dass eine KI ab einer bestimmten Intelligenzschwelle ein Bewusstsein erlangt. Anders als vielerorts angenommen hätte selbst ein Beweis dieser These keinerlei Auswirkungen auf die AKI-Forschung. Diese beschäftigt sich ausschließlich mit der Entwicklung und den Folgen einer AKI. Ein Szenario, in dem ein autonomes Fahrzeug eine Person X \emph{bewusst} vom Ort A zum Ort B chauffiert, wird zum gleichen Ergebnis führen wie ein Szenario, in dem selbiges \emph{unbewusst} geschieht. Somit ist der \emph{Bewusstseinszustand} einer AKI zwar noch nicht wissenschaftlich erforscht - damit beschäftigt sich ein eigenes Teilgebiet der KI-Forschung - , zum Erreichen einer sicheren KI ist er aber irrelevant. \vgl{noauthor_ai_nodate-1}
\subsection{Roboter als Auslöser einer Katastrophe}
Ein in der Populärliteratur besonders stark ausgeprägter Mythos ist jener einer existenziellen Bedrohung durch Roboter, die die Welt erobern. Geschuldet ist dies nicht nur den klassischen Science-Fiction-Romanen. Es ist eine domänenübergreifend anzutreffende Neigung der Spezies Mensch, Wesen oder Systeme, die einem unverständlich sind, zu vermenschlichen. Von den Wikingern, nach denen ein menschenähnliches Wesen namens Thor Donner und Blitz lenkt, zu den modernen Weltreligionen, in denen Antropomorphismus in selbigem Ausmaß gang und gäbe ist, ist dieses Phänomen schon seit jeher in der Geschichte des Menschen zu beobachten. Ich erkäre mir den Antropomorphismus als einen misslungenen Erklärungsversuch unseres Gehirns für unverständliche Beobachtungen.

Die größte Sorge der Forschung nach einer sicheren AKI gilt nicht möglichen Robotern, sondern der Intelligenz selbst, genauer gesagt einer Intelligenz, deren Ziele nicht eindeutig mit den unseren übereinstimmen. Intelligenz ermöglicht Kontrolle, und eine fortgeschrittene Intelligenz braucht auch keine Roboter, um ihre Ziele zu erreichen. Heutzutage reicht eine Internetverbindung völlig aus. \vgl{noauthor_ai_nodate-1}
\subsection{Bösartige AKI}
Eine AKI, deren Ziele nicht eindeutig mit den unseren übereinstimmen, ist nicht die Folge ihres \emph{bösartigen} Willens, sondern die Folge einer unzureichend spezifizierten Zielsetzung. Ein autonomes Fahrzeug, dessen alleiniges Ziel es ist, seine Insassen vom Ort A zum Ort B zu befördern, wird nicht auf die Gesundheit anderer Verkehrsteilnehmer achten, die Straßenverkehrsordnung nicht befolgen, nicht nur auf Straßen fahren, unangenehm Bremsen, unökologisch Beschleunigen und nicht nach den weiteren unzähligen, geschriebenen und ungeschriebenen menschlichen Werten und Normen handeln.

Es gibt keinen \emph{Geist in der Maschine}, der unser geschriebenes Programm durchliest und uns auf alle Stellen aufmerksam macht, die wir nicht so gemeint haben, wie wir sie geschrieben haben. Eine AKI ist nicht \emph{gut} oder \emph{böse}, sie folgt nur unseren Anweisungen. \vgl[1]{yudkowsky_complex_2011}

\section{Auswirkungen einer AKI}
\subsection{Destruktives Potential}
https://80000hours.org/podcast/episodes/allan-dafoe-politics-of-ai/
https://80000hours.org/topic/priority-paths/ai-policy/
\subsection{Machtverschiebung -und konzentration}
\subsection{Missbrauch}
%\section{KI-Ethik}
%Damit eine AKI ihre Ziele auf menschengewollte Art und Weise erfüllt, muss sie menschliche Werte teilen. Das folgende Kapitel behandelt Probleme bei einer etwaigen Werteformulierung.
%\subsection{Gesamtmenschheitlicher Konsens über gemeinsame Werte}
%
%Da eine mögliche AKI mit großer Wahrhscheinlichkeit globale Auswirkungen hätte, ist ein Miteinbeziehen der gesamten Meschheit unabdingbar.
%
%KOMMENTAR: Reflective Equilibrium; Ideal advisor Theory; EU-Richtlinien
%\subsection{\quotes{Gute} und \quotes{schlechte} menschliche Werte}
%KOMMENTAR:
%
%Selbst Forscher, die ein komsopolitisches Weltbild haben, das deutlich anders ist, als jenes der heutigen Gesellschaft, können das Nichteinbinden von menschlichen Werten nicht befürworten, denn dies würde schlimmere Folgen mit sich ziehen, als das Einbinden menschlicher Werte und die daraus resultierenden Negativfolgen in Form von systematischer Diskriminierung.
%\section{Demokratisierung einer AKI}
%\section{Maschinelle Werteanpassung}
\section{Verzerrungen}
\subsection{Verzerrung in der Risikoeinschätzung}
KOMMENTAR: Auch Zeitpunkt einer AKI
\subsection{Verzerrung in der Werteformulierung}
\subsection{Verzerrung in der Kodierung}
Nutzenfunktion (eng. \emph{utility function})

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "document"
%%% End:
