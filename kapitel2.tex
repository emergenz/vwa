% !TeX root = document.tex
\chapter{Probleme einer allgemeinen künstlichen Intelligenz}
Eine mögliche AKI bietet die Chance, die Lebensverhältnisse aller Menschen zu verbessern, birgt aber auch immense Gefahren, die nicht außer Acht gelassen werden dürfen. Mit Macht kommt auch immer Verantwortung. Es gilt schon jetzt Verantwortung zu übernehmen und Vorkehrungen zu treffen, um eine sichere AKI und einen positiven Effekt auf die Menschheit zu garantieren.
\section{Fehlerhafte Vorstellungen einer KI-Katastrophe}
\subsection{KI, die ein Bewusstsein erlangt}
In der Laienwelt sowie in großen Teilen der KI-Forschung ist eine These bekannt, die besagt, dass eine KI ab einer bestimmten Intelligenzschwelle ein Bewusstsein erlangt. Anders als vielerorts angenommen hätte selbst ein Beweis dieser These keinerlei Implikationen auf die AKI-Forschung. Diese beschäftigt sich ausschließlich mit der Entwicklung und den Folgen einer AKI. Ein Szenario, in dem ein autonomes Fahrzeug eine Person X \emph{bewusst} vom Ort A zum Ort B chauffiert, wird zum gleichen Ergebnis führen wie ein Szenario, in dem selbiges \emph{unbewusst} geschieht. Somit ist der \emph{Bewusstseinszustand} einer AKI zwar noch nicht wissenschaftlich erforscht - damit beschäftigt sich ein eigenes Teilgebiet der KI-Forschung - , zum Erreichen einer sicheren KI ist er aber irrelevant. \vgl{noauthor_ai_nodate-1}
\subsection{Roboter als Auslöser einer Katastrophe}
Ein in der Populärliteratur besonders stark ausgeprägter Mythos ist jener einer existenziellen Bedrohung durch Roboter, die die Welt erobern. Geschuldet ist dies nicht nur den klassischen Science-Fiction-Romanen. Es ist eine domänenübergreifend anzutreffende Neigung der Spezies Mensch, Wesen oder Systeme, die einem unverständlich sind, zu vermenschlichen. Von den Wikingern, nach denen ein menschenähnliches Wesen namens Thor Donner und Blitz lenkt, zu den modernen Weltreligionen, in denen Antropomorphismus in selbigem Ausmaß gang und gäbe ist, ist dieses Phänomen schon seit jeher in der Geschichte des Menschen zu beobachten. Trotz alledem ist der Antropomorphismus nichts anderes als ein misslungener Erklärungsversuch unseres Gehirns für unverständliche Beobachtungen.

Die größte Sorge der Forschung nach einer sicheren AKI gilt nicht möglichen Robotern, sondern der Intelligenz selbst, genauer gesagt einer Intelligenz, deren Ziele nicht eindeutig mit den unseren übereinstimmen. Intelligenz ermöglicht Kontrolle, und eine fortgeschrittene Intelligenz braucht auch keine Roboter, um ihre Ziele zu erreichen. Heutzutage reicht eine Internetverbindung völlig aus. \vgl{noauthor_ai_nodate-1}
\subsection{Bösartige AKI}
Eine AKI, deren Ziele nicht eindeutig mit den unseren übereinstimmen, ist nicht die Folge ihres \emph{bösartigen} Willens, sondern die Folge einer unzureichend spezifizierten Zielsetzung. Ein autonomes Fahrzeug, dessen alleiniges Ziel es ist, seine Insassen vom Ort A zum Ort B zu befördern, wird nicht auf die Gesundheit anderer Verkehrsteilnehmer achten, die Straßenverkehrsordnung nicht befolgen, nicht nur auf Straßen fahren, unangenehm Bremsen, unökologisch Beschleunigen und nicht nach den weiteren unzähligen, geschriebenen und ungeschriebenen menschlichen Werten und Normen handeln.

Es gibt keinen \emph{Geist in der Maschine}, der unser geschriebenes Programm durchliest und uns auf alle Stellen aufmerksam macht, die wir nicht so gemeint haben, wie wir sie geschrieben haben. Eine AKI ist nicht \emph{gut} oder \emph{böse}, sie folgt nur unseren Anweisungen. \vgl[1]{yudkowsky_complex_2011}
\section{Gesamtmenschheitlicher Konsens über gemeinsame Werte}
KOMMENTAR: Reflective Equilibrium; Ideal advisor Theory; EU-Richtlinien
\section{\quotes{Gute} und \quotes{schlechte} menschliche Werte}
Selbst Forscher, die ein komsopolitisches Weltbild haben, das deutlich anders ist, als jenes der heutigen Gesellschaft, können das Nichtinebinden von menschlichen Werten nicht befürworten, denn dies würde schlimmere Folgen mit sich ziehen, als das Einbinden menschlicher Werte und die daraus resultierenden Negativfolgen bezüglich Rassismus und anderen Vorurteilen.
\section{Wertekodierung in einer Programmiersprache}
KOMMENTAR: Complexity of Value Theory
\subsection{Statische Wertekodierung}
\subsection{Dynamisch-maschinelle Werteanpassung}
\section{Biases}
\subsection{Verzerrung in der Risikoeinschätzung}
KOMMENTAR: Auch Zeitpunkt einer AKI
\subsection{Verzerrung in der Werteformulierung}
\subsection{Verzerrung in der Kodierung}
Nutzenfunktion (eng. \emph{utility function})
\section{Sichere und vertrauenswürdige KI}
\vgl{yudkowsky_intelligence_2013}
\section{KI-Ethik}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "document"
%%% End:
