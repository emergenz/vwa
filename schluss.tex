% !TeX root = document.tex
\chapter{Schluss}
Der Meinungen der KI-Experten nach ist es sehr wahrscheinlich, dass die KI-Forschung bis 2075 zu einer AKI führt. \vgl[566]{muller_future_2016} Bis dahin muss eine Möglichkeit gefunden werden, eine AKI anzupassen. Menschliche Werte können nicht direkt in eine KI programmiert werden. Einerseits gibt es noch keine einheitlichen menschlichen Werte, weder national, noch international. Andererseits wäre ihre algorithmische Komplexität ohnehin zu groß. \vgl[13-14]{yudkowsky_intelligence_2013} Der Ansatz der KI-Sicherheit durch KI-Debatten, bei dem keine Wertedefinition oder -programmierung nötig ist, ist ein aussichtsreicher erster Schritt, dessen Funktionalität bei schwacher KI weiter getestet werden muss. Bei Entwicklung fähiger Dialogmodelle müssen diese in das Debattiersystem integriert werden. Um die negativen Eigenschaften einer anthropomorphen Maschine zu vermeiden, ist eine Lösung für das Problem der menschlichen Verzerrung notwendig. Dazu muss ein System gefunden werden, das über die spekulativen Ideen zur Verzerrungsminimierung von \citeauthor{irving_ai_2018} hinausgehen. Zudem ist die Regulation der AKI-Forschung unumgänglich, um die Entwicklung einer angepassten AKI zu gewährleisten. \vgl[16]{irving_ai_2018} Zu dessen Umsetzung braucht es eine internationale Institution, ein dezentralisiertes System ist heute noch nicht vorstellbar. \vgl{cihon_should_2019}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "document"
%%% End:
